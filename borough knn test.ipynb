{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "736140da",
   "metadata": {},
   "source": [
    "## Check Data availability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84050cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.data.source.socrata import Socrata\n",
    "\n",
    "for dataset in Socrata().catalog(domain='data.cityofnewyork.us'):\n",
    "    if 'OATH Hearings' in dataset.name.lower() and 'Division Case Status' in dataset.name.lower():\n",
    "        print(f'{dataset.identifier}\\t{dataset.domain}\\t{dataset.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e4fbf7",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fb2c4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'OATH Hearings Division Case Status' in file ./jz4z-kudi.tsv.gz of size 478.98 MB\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import humanfriendly\n",
    "import os\n",
    "\n",
    "dataset = Socrata().dataset('jz4z-kudi')\n",
    "datafile = './jz4z-kudi.tsv.gz'\n",
    "\n",
    "if not os.path.isfile(datafile):\n",
    "    with gzip.open(datafile, 'wb') as f:\n",
    "        print('Downloading ...\\n')\n",
    "        dataset.write(f)\n",
    "        \n",
    "fsize = humanfriendly.format_size(os.stat(datafile).st_size)\n",
    "print(\"Using '{}' in file {} of size {}\".format(dataset.name, datafile, fsize))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e97656e",
   "metadata": {},
   "source": [
    "## Read Data as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea16bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openclean.pipeline import stream\n",
    "df = stream(os.path.join('data', 'jz4z-kudi.tsv.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4024b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vlb = df.select('violation_location_borough').distinct()\n",
    "\n",
    "print('{} distinct boroughs (for {} total values)'.format(len(vlb), sum(vlb.values())))\n",
    "from openclean.cluster.knn import knn_clusters\n",
    "from openclean.function.similarity.base import SimilarityConstraint\n",
    "from openclean.function.similarity.text import LevenshteinDistance\n",
    "from openclean.function.value.threshold import GreaterThan\n",
    "minsize = 5\n",
    "\n",
    "clusters = knn_clusters(\n",
    "    values=vlb,\n",
    "    sim=SimilarityConstraint(func=LevenshteinDistance(), pred=GreaterThan(0.9)),\n",
    "    minsize=minsize\n",
    ")\n",
    "print('{} clusters of size {} or greater'.format(len(clusters), minsize))\n",
    "def print_cluster(cnumber, cluster):\n",
    "    print('Cluster {} (of size {})\\n'.format(cnumber, len(cluster)))\n",
    "    for val, count in cluster.items():\n",
    "        print('{} ({})'.format(val, count))\n",
    "    print('\\nSuggested value: {}\\n\\n'.format(cluster.suggestion()))\n",
    "\n",
    "\n",
    "clusters.sort(key=lambda c: len(c), reverse=True)\n",
    "\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print_cluster(i + 1, cluster)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
